{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## edna2qiime.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first sheet from each Excel file\n",
    "studyMetadata = pd.read_excel('/Users/luke.thompson/node/test-data/studyMetadata_gomecc4.xlsx', sheet_name=0)\n",
    "sampleMetadata = pd.read_excel('/Users/luke.thompson/node/test-data/sampleMetadata_gomecc4.xlsx', sheet_name=0, comment='#')\n",
    "libraryMetadata = pd.read_excel('/Users/luke.thompson/node/test-data/libraryMetadata_gomecc4.xlsx', sheet_name=0, comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor studyMetadata to get the last 4 columns, set field_name column as the index, and transpose the DataFrame\n",
    "last_four_columns = studyMetadata.iloc[:, -4:]\n",
    "last_four_columns.set_index('field_name', inplace=True)\n",
    "studyMetadataT = last_four_columns.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From studyMetadataT, get the project_id\n",
    "project_id = studyMetadataT['project_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From libraryMetadata get the unique values of the 'seq_run_id' and 'assay_name' columns\n",
    "seq_run_ids = libraryMetadata['seq_run_id'].unique()\n",
    "assay_names = libraryMetadata['assay_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the values of 'assay_name' are the same in studyMetadata and libraryMetadata\n",
    "set(assay_names) == set(studyMetadataT['assay_name'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict of DataFrames to store the merged DataFrames\n",
    "merged_dfs = {}\n",
    "\n",
    "for runID in seq_run_ids:\n",
    "    for assay in assay_names:\n",
    "        # Get the subset of libraryMetadata for the current 'seq_run_id' and 'assay_name'\n",
    "        libraryMetadata_subset = libraryMetadata[(libraryMetadata['seq_run_id'] == runID) & (libraryMetadata['assay_name'] == assay)]\n",
    "        # Merge the subset of libraryMetadata with sampleMetadata using 'samp_name' as the key and add to list of merged DataFrames\n",
    "        merged = pd.merge(libraryMetadata_subset, sampleMetadata, left_on='samp_name', right_on='samp_name')\n",
    "        # If the merged DataFrame is not empty, continue\n",
    "        if merged.shape[0] > 0:\n",
    "            # Create a dictionary to hold the new columns\n",
    "            new_columns = {}\n",
    "            # Add each column from studyMetadataT to the dictionary\n",
    "            for column in studyMetadataT.columns:\n",
    "                new_columns[column] = studyMetadataT.loc['study_level', column]\n",
    "                if not pd.isna(studyMetadataT.loc[assay, column]):\n",
    "                    new_columns[column] = studyMetadataT.loc[assay, column]\n",
    "            # Convert the dictionary to a DataFrame and repeat it for each row in the merged DataFrame\n",
    "            new_columns_df = pd.DataFrame(new_columns, index=merged.index)\n",
    "            # Concatenate the new columns DataFrame with the merged DataFrame\n",
    "            merged = pd.concat([merged, new_columns_df], axis=1)\n",
    "            # Drop columns that contain only NaN values\n",
    "            merged = merged.dropna(axis=1, how='all')\n",
    "            # Add merged DataFrame to the dict of merged DataFrames\n",
    "            merged_dfs[(runID, assay)] = merged\n",
    "            # Save the merged DataFrame to a tab-delimited file and drop the index column\n",
    "            merged.to_csv(f'{project_id}.{runID}.{assay}.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
